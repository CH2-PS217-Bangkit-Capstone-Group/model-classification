{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab specific steps\n",
    "from google.colab import files, drive\n",
    "files.upload()\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d adikurniawan/color-dataset-for-color-recognition/\n",
    "with zipfile.ZipFile('color-dataset-for-color-recognition.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/kaggle/input/color-dataset-for-color-recognition/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    flipped_horizontally = cv2.flip(image, 1)\n",
    "    return [image, flipped_horizontally]\n",
    "\n",
    "rgb, hsv, color = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(os.path.join(dirname, filename))\n",
    "        image_rgb, image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2RGB), cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        for img in augment_image(image_rgb):\n",
    "            rgb.append(img[0][0])\n",
    "            color.append(dirname.split('/')[-1])\n",
    "\n",
    "        for img in augment_image(image_hsv):\n",
    "            hsv.append(img[0][0])\n",
    "\n",
    "rgb_df, hsv_df, color_df = pd.DataFrame(np.array(rgb), columns=['red', 'green', 'blue']), \\\n",
    "                           pd.DataFrame(np.array(hsv), columns=['hue', 'saturation', 'value']), \\\n",
    "                           pd.DataFrame({'color': color})\n",
    "\n",
    "df = pd.concat([rgb_df, hsv_df, color_df], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.3, random_state=0)\n",
    "\n",
    "def build_knn_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_knn_model(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    y_encoded = pd.get_dummies(y)\n",
    "\n",
    "    input_dim, output_dim = X_scaled.shape[1], y_encoded.shape[1]\n",
    "    model = build_knn_model(input_dim, output_dim)\n",
    "\n",
    "    model.fit(X_scaled, y_encoded, epochs=10000, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "knn_model, scaler = train_knn_model(X_train, y_train)\n",
    "dump(knn_model, 'knn_model.h5')\n",
    "dump(scaler, 'scaler.joblib')\n",
    "\n",
    "loaded_knn_model = load_model('knn_model.h5')\n",
    "loaded_scaler = load('scaler.joblib')\n",
    "\n",
    "y_pred = np.argmax(loaded_knn_model.predict(loaded_scaler.transform(X_test)), axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Loaded Model Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
